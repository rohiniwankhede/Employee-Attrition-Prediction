# -*- coding: utf-8 -*-
"""Attrition Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yKrpimk7dBG8p9gciI3Z5_fvKsKZ9WMg
"""

df = pd.read_excel("/content/Attrition_Database1 1.xlsx")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df

df.shape

df.info()

df.isnull().sum()

df.isna().sum()

df.duplicated().sum()

df.columns

df['Attrition'].value_counts()

sns.countplot(x='Attrition', data=df)
plt.show()

"""Count Distribution of Overtime to Attrition"""

pd.crosstab(df['OverTime'], df['Attrition'])   # OverTime = No
                                               # Total = 902 + 188 = 1090
                                               # Attrition Yes = 188
                                               # Attrition rate = 17.2%
                                                                           # we did not got huge difference in attrition rate
                                                                           # This feature may not be that useful for prediction
                                               # OverTime = Yes
                                               # Total = 760 + 150 = 910
                                               # Attrition Yes = 150
                                               # Attrition rate = 16.5%

"""Count Distribution of Gender to  Attrition"""

pd.crosstab(df['gender'], df['Attrition'])   #Female
                                             # Total = 694 + 145 = 839
                                             # Attrition rate =
                                             # 145 / 839 = 17.3%
                                                                         # we did not got huge difference in attrition rate
                                                                         # This feature may not be that useful for prediction
                                              #Male
                                              # Total = 968 + 193 = 1161
                                              # Attrition rate =
                                              # 193 / 1161 = 16.6%

"""Count Distribution of  Marital Status to Attrition"""

pd.crosstab(df['MaritalStatus'], df['Attrition'])   #Divorced
                                                    #Total = 545 + 111 = 656
                                                    #Attrition rate  = 111 / 656 ≈ 16.9%

                                                    #Married
                                                    #Total = 569 + 116 = 685
                                                    #Attrition rate ≈
                                                    #116 / 685 ≈ 16.9%
                                                                                 #ALMOST SAME ATTRITION RATE , SO MAY NOT BE USEFUL FOR PREDICTION
                                                    # Single
                                                    #Total = 548 + 111 = 659
                                                    #Attrition rate ≈
                                                    #111 / 659 ≈ 16.8%

"""Distribution of Monthly Income to Attrition"""

df.groupby('Attrition')['MonthlyIncome'].describe()
                                                        #min max value almost same
                                                        #std also almost same
                                                        #MonthlyIncome does not show a strong individual relationship with attrition

"""Distribution of Tenure to Attrition"""

df.groupby('Attrition')['Tenure'].describe()  #mean max Tenure almost same
                                              #std also almost same
                                              # so Tenure may not be that useful for prediction

"""Distribution of Avg Week Hours to Attrition"""

df.groupby('Attrition')['AverageWeeklyHours'].describe()  #mean AverageWeeklyHours almost same
                                                            #std also almost same
                                                            # so AverageWeeklyHours may not be that useful for prediction

"""Distribution of Employee_Engagement_Score to Attrition"""

df.groupby('Attrition')['Employee_Engagement_Score'].describe()  #Attrition = No - scores tightly around 4–5
                                                                 #Attrition = Yes - scores mostly 1–3

                                                                # Employee engagement score has a strong inverse relationship with attrition.
                                                                # Employees with low engagement are significantly more likely to leave.

sns.boxplot(x='Attrition', y = 'Employee_Engagement_Score' , data = df)
plt.title('Employee Engagement Score vs Attrition')
plt.show()

# There is a clear separation between engagement scores of employees who stayed and those who left.

df = df.drop(columns=['DateOfJoining']) #Dropping DateOfJoining column as it is not useful for prediction

df.columns

"""Data Preprocessing"""

df['Attrition']= df['Attrition'].map({'Yes':1,'No':0}) #here we are mapping yes to 1 and no to 0 for better understanding

df['Attrition'].value_counts()    #cheking value count after mapping

df.columns

cat_cols = ['gender','EmploymentType','OverTime'] #made a list of categorical text columns

from sklearn.preprocessing import LabelEncoder #importing lebelencoder from sklearn for lableecoding

"""Lable Encoding"""

le = LabelEncoder()  #calling lebelencoder function

for col in cat_cols :
    df[col] = le.fit_transform(df[col])

df[cat_cols].head()                   #for gender colmun -  (female = 0 , male = 1 )
                      #Encodeing      #for employment type - (full time = 0 , part time = 1 )
                                      #for overtime - (no = 0 , yes = 1 )

multi_cat_cols = ['department','jobrole','designation','MaritalStatus','EducationLevel']  #made a list of multi categorical text columns

"""One Hot Encoding"""

df = pd.get_dummies(df, columns = multi_cat_cols , drop_first= True)

 #using get dummies function to convert multi categorical text columns to numerical columns

df.columns

"""Feature Scaling"""

x = df.drop('Attrition', axis = 1 )  #independent features
y = df['Attrition']                  #dependent features

"""Train–Test split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(x ,y , test_size = 0.2 , random_state = 42 , stratify = y)

"""Scaling"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()                                        #scaling the data using standard scaler

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""**Logistic Regression**"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000)     #calling logistic regression model with max iteration 1000 beacause data is large

lr.fit(X_train_scaled , y_train)          #Due to NAN value in some columns we are not able to fit the model

import numpy as np

print('Number of NaNs in X_test:', np.isnan(X_test).sum())

np.isnan(X_train_scaled).sum()  #we got 5 NAN values in X_train_scaled after scaling

X_train.isnull().sum().sort_values(ascending=False).head(10)

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy = 'median')
                                                    #here we are using simple imputer to fill the NAN values with median of that column
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)      # here we scaled the data after imputing the NAN values
X_test_scaled = scaler.transform(X_test)

np.isnan(X_train_scaled).sum()  #now we got 0 NAN values after imputing

lr.fit(X_train_scaled , y_train) #training the model

y_test_pred = lr.predict(X_test_scaled)
y_train_pred = lr.predict(X_train_scaled)      #predicting the values

from sklearn.metrics import accuracy_score

Test_acc = accuracy_score(y_test , y_test_pred)
Train_acc = accuracy_score(y_train , y_train_pred)         #here we are calculating accuracy for both test and train data
                                                           # and we found that model is not overfitting as both accuracies are almost same
print('Test Accuracy : ', Test_acc)
print('Train Accuracy : ', Train_acc)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test , y_test_pred)                               #after getting accuracy we are checking confusion matrix
                                                                          #in our case FN is 0 which is good
                                                                          #this shows that our model is performing well
                                                                          #employees who are likely to leave are correctly identified
sns.heatmap(cm , annot= True , fmt= 'd' , cmap = 'Blues')
plt.xlabel('predicted')
plt.ylabel('Actual')
plt.show()

from sklearn.metrics import classification_report

print(classification_report(y_test , y_test_pred))

"""***“Logistic Regression performed extremely well because employee engagement score showed a very strong separation between employees who stayed and those who left.”***

**Decision Tree Algorithm**
"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42, max_depth=5)    #calling decision tree classifier with max depth 5 to avoid overfitting

dt.fit(X_train_scaled , y_train)                             #fitting the model

"""Prediction"""

y_test_pred = lr.predict(X_test_scaled)

y_train_pred = lr.predict(X_train_scaled)

"""Model Evolution"""

test_acc = accuracy_score(y_test , y_test_pred)
train_acc = accuracy_score(y_train , y_train_pred)
                                                        #checking overfitting by calculating accuracy for both test and train data
print('Test Accuracy : ' ,test_acc)
print('Train Accuracy : ' , train_acc)

"""Confusion Matrix"""

cm = confusion_matrix(y_test , y_test_pred)

sns.heatmap(cm , annot = True , fmt = 'd' , cmap = 'Greens')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print(classification_report(y_test, y_test_pred))

"""**Random Forest Algorithm**"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state = 42 , n_estimators = 100 , max_depth=5 )
                                                     #calling random forest classifier with n_estimators 100 and max depth 5 to avoid overfitting
rf.fit(X_train_scaled , y_train)

"""Prediction"""

y_test_pred = rf.predict(X_test_scaled )

y_train_pred = rf.predict(X_train_scaled)

"""Model Evolution"""

Test_acc = accuracy_score(y_test , y_test_pred)
                                                            #checking overfitting by calculating accuracy for both test and train data
Train_acc = accuracy_score(y_train , y_train_pred)

print('Test Accuracy : ' ,Test_acc)
print('Train Accuracy : ' ,Train_acc)

"""Confusion Matrix"""

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test , y_test_pred)                               #after getting accuracy we are checking confusion matrix
                                                                          #in our case FN is 0 which is good
                                                                          #this shows that our model is performing well
                                                                          #employees who are likely to leave are correctly identified
sns.heatmap(cm , annot= True , fmt= 'd' , cmap = 'Reds')
plt.xlabel('predicted')
plt.ylabel('Actual')
plt.show()

print(classification_report(y_test , y_test_pred))

"""**Conclusion**

***In this project, I analyzed employee attrition data, performed preprocessing, and trained multiple machine learning models.
All models showed similar and high performance, indicating strong patterns in the data.
The Logistic Regression model was selected as the final model due to its simplicity, stability, and good predictive performance.***
"""

